{"posts":[{"title":"Implementation of nested set design of SQL with Java - Nested Set Modified Preorder Tree Traversal","text":"简体中文 PreviousRecently, we got a requirement for storage directories and files，the condition is, Input parameter is the path of the root directory which was unpacked. The files will not change nor update after unpacked. The details of the requirement is, The directories and all its subdirectories and sub-files need to be parsed into a tree structure response to the front end. When the user clicks on each level of directory, we need to get the files in this directory and all its subdirectories for some business data statistics. We can only use the MySQL.(Can’t use a graph database.) After research, the found that nested set design is well suited for such a scenario.1Note - If graph databases are used in the project, graph databases are a better choice for handling complex hierarchical data. It is hard to find ready-made code on the Internet that uses Java to implement this, and only found a project on github that implements part of the functionality. However, this project does not support MyBatis and I do not plan to adopt it, so I can only implement the nested set design by myself. This article will briefly introduce the Nested Set Model Nested Set Model, details of how to use Java, from the table to the library to implement the nested set model. The examples in this article use MySQL 8.0, JDK 8. Nested Set ModelWhen faced with hierarchically structured data stores, such as catalogs, ! catalog storage We tend to use the scheme known as the neighboring table model with table field designs of approx:1id, name, parentIdIn the adjacency table, all data has a parentId field to store its parent node ID. if the current node is the root node, its parent node is NULL or -1. When traversing, you can use recursion to query the whole tree, but also easy to query the next level of nodes. It is also easy to add and delete. However, when the amount of data is large, querying the whole tree will affect performance, and even lead to memory overflow.Therefore, in use, we usually use lazy loading to show the data one level at a time. Or limit the depth of the recursion to show only part of the data. If the known data additions, deletions and changes are rare, the query performance requirements are relatively high, and like our needs, we need to check all the leaf nodes under a node, you can consider using the nested set model. The design of the nested set model is approximately:1id, name, left_index, right_index, depthIn other words, this views the individual nodes as individual containers, with the child nodes inside the parent node and all nodes in the root node; represented in a picture as follows: Then numbered from left to right, each container has a left and right two numbers, that is, for the left and right; represented by the picture as follows: To make it easier to query the next level node and other nodes, a depth field can be added to indicate the depth.At this point, the left and right values of each node can be obtained.Below are just a few of the most commonly used SQLs. Other SQLs can be found in Managing Hierarchical Data in MySQL. Implemented in JavaMySQL Table Design123456789101112CREATE TABLE `file_nested_sets_demo` ( `id` varchar(100) NOT NULL COMMENT 'Document ID，unique identifier', `path` varchar(2000) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL COMMENT 'Full path of the file', `type` varchar(100) DEFAULT NULL COMMENT 'Document type; Directory,File', `size` double DEFAULT NULL COMMENT 'file size', `tree_id` bigint DEFAULT NULL, `left_index` bigint NOT NULL, `right_index` bigint NOT NULL, `depth` bigint NOT NULL, PRIMARY KEY (`id`), KEY `idx_tree_id_indexes` (`tree_id`,`left_index`,`right_index`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='文件嵌套集表示例'; Constructing mapping entities123456789101112131415161718192021222324252627282930313233/** * Nested set objects used by the deposit database */public class FileNestedSetsDemo { /** * Document ID, unique identification */ private String id; /** * Full path of the file */ private String path; /** * Document type; FILE/DIRECTORY */ private String type; /** * file size */ private Double size; private Long treeId; private Long leftIndex; private Long rightIndex; private Long depth;} Data number entryThe input data is known to be a file path, and the path structure is the same as in the above figure, for example:123456789101112|== means folder; |-- means file. |==resources |==data |--table_design |==mapper |==server |--ServerMapper.xml |==source |--AMapper.xml |--bootstrap.properties |--logback-spring.xml The expected output is:1234567891011depth left_index|||path|||right_index0 1|||\\resources|||201 2|||\\resources\\data||52 3|||\\resources\\data\\table_design|||41 6|||\\resources\\mapper|||152 7|||\\resources\\mapper\\server|||103 8|||\\resources\\mapper\\server\\ServerMapper.xml|||92 11|||\\resources\\mapper\\source|||122 13|||\\resources\\mapper\\AMapper.xml|||141 16|||\\resources\\bootstrap.properties|||171 18|||\\resources\\logback-spring.xml|||19 We can construct the data using the precedence traversal algorithm, traversing its children and assigning values from left to right, one layer at a time.The following code uses a depth-first approach to traverse the directory and assign values, returning Map. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class NestedSetsUtil { /** *Use depth-first traversal of the catalog to return Map, which is used to support nested set initial entry. * * @param root Directories to be traversed * @return Map&lt;File, NestedSetObj&gt; **/ public static Map&lt;File, NestedSetObj&gt; dfs2NestedSets(File root) { if (root == null) { return new HashMap&lt;&gt;(0); } // Record Depth -1 per stack out, +1 per stack in. long depth = 0L; // left and right values long index = 1L; Deque&lt;File&gt; stack = new ArrayDeque&lt;&gt;(); stack.push(root); // A global collection of objects that also indicates whether this object has been on the stack. Map&lt;File, NestedSetObj&gt; map = new LinkedHashMap&lt;&gt;(); // root directory NestedSetObj rootObj = NestedSetObj.builder().path(root.getAbsolutePath()).depth(depth).left(index++).build(); map.put(root, rootObj); while (!stack.isEmpty()) { File cur = stack.pop(); depth--; File[] files = cur.listFiles(); if (files != null) { for (File next : files) { // if the next node hasn't been visited before if (!map.containsKey(next)) { //Stack the current and the next nodes depth++; stack.push(cur); depth++; stack.push(next); // Assign left value to node on first visit NestedSetObj obj = NestedSetObj.builder().left(index++).path(next.getAbsolutePath()).depth(depth).build(); boolean leaf = !next.isDirectory(); boolean emptyDirLeaf = next.listFiles() != null &amp;&amp; next.listFiles().length == 0; //Assign right value to leaf node or empty directory. if (leaf || emptyDirLeaf) { obj.setRight(index++); } map.put(next, obj); break; } } // Determine whether the leaf node's right needs to be assigned a value; //The current directory can only be assigned a value if all the data in all the child levels have a RIGHT value. long min = Long.MAX_VALUE; for (File file : files) { NestedSetObj childObject = map.get(file); if (childObject == null) { min = 0L; break; } min = Math.min(min, childObject.getRight()); } // Assign a value to the right of a non-leaf node. // When the first-level child nodes all have a right value, index+1 is the current node's right value. if (min &gt; 0L &amp;&amp; Long.MAX_VALUE != min) { if (min &gt; 0L &amp;&amp; Long.MAX_VALUE != min) { NestedSetObj curObj = map.get(cur); if (curObj.right == 0L) { curObj.setRight(index++); } } } } //Right value of root = nodes * 2 rootObj.setRight(map.size() * 2L); return map; } /** * Document nested set of objects, business-agnostic */ public static class NestedSetObj { private long left; private long right; private long depth; private String path; }} Then just traverse the data from the NestedSetsUtil#dfs2NestedSets() response, assign it to FileNestedSetsDemo, and batch into the library. Query data based on business requirements Retrieve all child nodes of type file under a single path 12345678910SELECT node.*FROM file_nested_sets_demo AS node, file_nested_sets_demo AS parentWHERE node.depth = parent.depth + 1 AND node.left_index &gt; parent.left_index AND node.right_index &lt; parent.right_index AND node.tree_id = 1 AND parent.path = '\\resources\\mapper' AND node.type = 'FILE'ORDER BY parent.left_index Retrieve all child nodes under a single tree 1234SELECT node.*FROM file_nested_sets_demo AS nodeWHERE node.tree_id = 1ORDER BY node.left_index Extended Query Statements Retrieve direct child nodes under a single path 123456789SELECT node.*FROM file_nested_sets_demo AS node, file_nested_sets_demo AS parentWHERE node.depth = parent.depth + 1 AND node.left_index &gt; parent.left_index AND node.right_index &lt; parent.right_index AND node.tree_id = 1 AND parent.path = '\\resources\\mapper'ORDER BY parent.left_index NoteThe Java algorithms that can be executed can be found in GitHub","link":"/2022/03/28/nested-set-modified-preorder-tree-traversal-realizing-sql-nested-set-design-in-java/"},{"title":"Single Node ElasticSearch and Kibana Installation Instructions","text":"简体中文 Summary Setup ES 安装Kibana 配置权限(使用用户名和密码身份验证运行本地集群) 附录 SummaryTo support the new features, we have added ES nodes. You can configure ES as a single node or cluster depending on the data situation and status; enable Xpack, enable permission authentication (requires Kibana installation).The official documentation Set up Elasticsearch has installation instructions for each OS, Installing Elasticsearch page provides links to instructions for various installation packages, which can be consulted. This document provides instructions for installing ES and Kibana on a single-node Linux server. Setup ES First make sure you have a JDK in your environment. Elasticsearch 7.x package includes the OpenJDK11 package, if you need to use your own version, refer to the official documentation to set the JAVA_HOME environment variable. Create an ES-specific user, as it is not possible to start with root user. 1useradd elasticsearch Create the ES directory and grant permissions to the elasticsearch user. 123cd /homemkdir /eschown -R elasticsearch:elasticsearch /home/es/ Upload elasticsearch-7.14.0-linux-x86_64.tar.gz in the zip archive, or you can go to the official website to download it or use other methods to download it. Unpacked 1tar -zxvf elasticsearch-7.14.0-linux-x86_64.tar.gz Modify the configuration file and go to the unpacked directory 1cd elasticsearch-7.14.0/config First backup the configuration file elasticsearch.yml, and then modify 12345678cp elasticsearch.yml elasticsearch.yml.bak vim elasticsearch.yml------------------------------network.host: ${ip of this server}http.port: 9200discovery.seed_hosts: [&quot;${ip of this server}&quot;]discovery.type: single-node # single-node mode------------------------------ Open ports of 9200 and 9300, or turn off the firewall. 根据配置文件，创建data目录存储es数据 1mkdir data 给ES用户所有ES相关的权限；切换到elasticsearch用户；在bin目录下启动ES 1234chown -R elasticsearch:elasticsearch ./*su – elasticsearchcd /home/es/elasticsearch-7.14.0/bin./elasticsearch &amp; 启动后可能会出现报错： 12trying to update state on non-existing task geoip-downloader[2021-08-11T15:33:57,318][ERROR][o.e.i.g.GeoIpDownloader ] [18789989a729] error updating geoip database [GeoLite2-Country.mmdb] 该报错可以忽略；若想解决请看附录 1.解决ES启动报错问题 验证启动情况，在本机执行 1curl http://${ip}:9200/ 得到返回结果如: 1234567891011121314151617{ &quot;name&quot; : &quot;localhost.localdomain&quot;, &quot;cluster_name&quot; : &quot;oss-es&quot;, &quot;cluster_uuid&quot; : &quot;HKCnF4l_TOSW8-mznxM5eg&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;7.14.0&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;dd5a0a2acaa2045ff9624f3729fc8a6f40835aa1&quot;, &quot;build_date&quot; : &quot;2021-07-29T20:49:32.864135063Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.9.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot;} 即为成功！ 再尝试通过浏览器访问http://${ip}:9200/有相同的响应成功结果。 若无法访问，则检查防火墙。 安装Kibana 安装步骤可参考官方网站；或按以下步骤执行 使用root用户，上传压缩包内的kibana-7.14.0-linux-x86_64.tar.gz并解压。 1tar -zxvf kibana-7.14.0-linux-x86_64.tar.gz 进入目录备份配置文件kibana.yml，而后修改 123456789cd kibana-7.14.0-linux-x86_64/config/cp kibana.yml kibana.yml.bakvim kibana.yml ------------------------------server.port: 5601server.host: &quot;${该服务器的ip}&quot;elasticsearch.hosts: [&quot;http://${ES服务所在IP}:9200&quot;]elasticsearch.username: &quot;kibana_system&quot;------------------------------ 进入/bin 目录启动 12cd ../bin./kibana 界面会打印日志，最后出现如下所示内容，即为成功！ 1Kibana is now available 可通过浏览器访问 http://ip:5601 配置权限(使用用户名和密码身份验证运行本地集群) 可以参考官网最低安全性设置 停止 Kibana 和 Elasticsearch（如果它们正在运行） 将 xpack.security.enabled 设置添加到$ES_PATH_CONF/elasticsearch.yml文件并将值设置为true 12345 cd /home/es/elasticsearch-7.14.0/config vim elasticsearch.yml-----添加以下信息-------xpack.security.enabled:true---------------------- tips:该$ES_PATH_CONF变量是 Elasticsearch 配置文件的路径。如果您使用存档分发版（zip或tar.gz）安装了 Elasticsearch ，则该变量默认为$ES_HOME/config. 如果您使用软件包发行版（Debian 或 RPM），则该变量默认为/etc/elasticsearch. 启动ES，等待启动成功 12cd ../bin./elasticsearch 打开另一个终端窗口，进入ES目录，执行命令启用配置密码工具 1./bin/elasticsearch-setup-passwords interactive 执行后根据命令行提示配置密码 配置 Kibana 以使用密码连接到 Elasticsearch ，创建 Kibana 密钥库并添加安全设置： 123cd kibana-7.14.0-linux-x86_64/ ./bin/kibana-keystore create ./bin/kibana-keystore add elasticsearch.password 出现提示时，输入kibana_system用户的密码。 重启 Kibana,并在浏览器 “http://${kibanaIp}:5601” 以elastic用户身份登录 Kibana 。 1./bin/kibana 附录 解决ES启动报错问题 参考 How to disable geoip usage in 7.14.0方案：使用 cluster settings API 而不是 elasticsearch.yml; 即安装好Kibana后，执行123456PUT _cluster/settings{ &quot;persistent&quot;: { &quot;ingest.geoip.downloader.enabled&quot;: false }}","link":"/2021/12/02/single-node-elasticsearch-and-kibana-installation-instructions/"}],"tags":[{"name":"SQL, Tree traversal, Project Experience, Java, System Design","slug":"SQL-Tree-traversal-Project-Experience-Java-System-Design","link":"/tags/SQL-Tree-traversal-Project-Experience-Java-System-Design/"}],"categories":[{"name":"Technology","slug":"Technology","link":"/categories/Technology/"},{"name":"ops","slug":"ops","link":"/categories/ops/"}],"pages":[{"title":"About","text":"简体中文 The solution of the problem of life is seen in the vanishing of this problem.(Is not this the reason why men to whom after long doubting the sense of life became clear, could not then say wherein this sense consisted?) Ludwig WittgensteinTractatus Logico-Philosophicus BoBoTheKnightWelcome to BoBoTheKnight’s site! I learn and think often out of curiosity. Although the answers to many questions are unspeakable, I still want to share my learning and thinking process.To record my growth. If possible, help more people with the same confusion. Of course, I will also share some technical articles in here.BTW, even I named myself knight, I wish world peace. CreditI want to thank a few people without whom I would have had a hard time building this site.Thanks to GitHub for code hosting!Thanks to Hexo for the blog project!Thanks to Icarus for the pretty theme!Thanks to FontAwesome for the icons!Thanks to FlatIcon for the icons, especially thanks to the following talented authors, they are :&nbsp;&nbsp;&nbsp;&nbsp; Freepik for the Knight and the Peace icons!&nbsp;&nbsp;&nbsp;&nbsp; Trazobanana for the LGBT icons!&nbsp;&nbsp;&nbsp;&nbsp; Rashad for the Peace icons!","link":"/about/index.html"}]}